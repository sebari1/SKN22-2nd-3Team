{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4db6b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë”¥ëŸ¬ë‹ ë°ì´í„° ì¤€ë¹„ ì¤‘...\n",
      "í•™ìŠµ ë°ì´í„°ì—ë§Œ SMOTE ì ìš© ì¤‘... (ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ë³´ì¡´)\n",
      "\n",
      "ëª¨ë¸ êµ¬ì¡°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. (ì…ë ¥ ì°¨ì›: 20)\n",
      "í•™ìŠµ ì‹œì‘...\n",
      "Epoch 1/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5918 - loss: 0.7713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6446 - loss: 0.6914 - val_accuracy: 0.4990 - val_loss: 0.6779 - learning_rate: 5.0000e-04\n",
      "Epoch 2/250\n",
      "\u001b[1m115/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7236 - loss: 0.5676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.5753 - val_accuracy: 0.6220 - val_loss: 0.6311 - learning_rate: 5.0000e-04\n",
      "Epoch 3/250\n",
      "\u001b[1m119/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7432 - loss: 0.5388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7479 - loss: 0.5304 - val_accuracy: 0.7210 - val_loss: 0.5473 - learning_rate: 5.0000e-04\n",
      "Epoch 4/250\n",
      "\u001b[1m121/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7744 - loss: 0.5060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7655 - loss: 0.5152 - val_accuracy: 0.7440 - val_loss: 0.5172 - learning_rate: 5.0000e-04\n",
      "Epoch 5/250\n",
      "\u001b[1m116/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7699 - loss: 0.4958 - val_accuracy: 0.7545 - val_loss: 0.5035 - learning_rate: 5.0000e-04\n",
      "Epoch 6/250\n",
      "\u001b[1m120/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.4939 - val_accuracy: 0.7605 - val_loss: 0.4908 - learning_rate: 5.0000e-04\n",
      "Epoch 7/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 0.4933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 0.4822 - val_accuracy: 0.7610 - val_loss: 0.4877 - learning_rate: 5.0000e-04\n",
      "Epoch 8/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.4796 - val_accuracy: 0.7600 - val_loss: 0.4845 - learning_rate: 5.0000e-04\n",
      "Epoch 9/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.4711 - val_accuracy: 0.7590 - val_loss: 0.4882 - learning_rate: 5.0000e-04\n",
      "Epoch 10/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.4660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.4735 - val_accuracy: 0.7640 - val_loss: 0.4854 - learning_rate: 5.0000e-04\n",
      "Epoch 11/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4683 - val_accuracy: 0.7625 - val_loss: 0.4707 - learning_rate: 5.0000e-04\n",
      "Epoch 12/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.4697 - val_accuracy: 0.7625 - val_loss: 0.4768 - learning_rate: 5.0000e-04\n",
      "Epoch 13/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7977 - loss: 0.4629 - val_accuracy: 0.7610 - val_loss: 0.4794 - learning_rate: 5.0000e-04\n",
      "Epoch 14/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4575 - val_accuracy: 0.7580 - val_loss: 0.4832 - learning_rate: 5.0000e-04\n",
      "Epoch 15/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4523 - val_accuracy: 0.7595 - val_loss: 0.4866 - learning_rate: 5.0000e-04\n",
      "Epoch 16/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.4530 - val_accuracy: 0.7600 - val_loss: 0.4847 - learning_rate: 5.0000e-04\n",
      "Epoch 17/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4487 - val_accuracy: 0.7610 - val_loss: 0.4783 - learning_rate: 5.0000e-04\n",
      "Epoch 18/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.4494 - val_accuracy: 0.7570 - val_loss: 0.4845 - learning_rate: 5.0000e-04\n",
      "Epoch 19/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4460 - val_accuracy: 0.7640 - val_loss: 0.4820 - learning_rate: 5.0000e-04\n",
      "Epoch 20/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.4443 - val_accuracy: 0.7590 - val_loss: 0.4823 - learning_rate: 5.0000e-04\n",
      "Epoch 21/250\n",
      "\u001b[1m118/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4496 - val_accuracy: 0.7665 - val_loss: 0.4707 - learning_rate: 5.0000e-04\n",
      "Epoch 22/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8033 - loss: 0.4413 - val_accuracy: 0.7660 - val_loss: 0.4758 - learning_rate: 2.5000e-04\n",
      "Epoch 23/250\n",
      "\u001b[1m121/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.4395 - val_accuracy: 0.7670 - val_loss: 0.4755 - learning_rate: 2.5000e-04\n",
      "Epoch 24/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4371 - val_accuracy: 0.7620 - val_loss: 0.4863 - learning_rate: 2.5000e-04\n",
      "Epoch 25/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4347 - val_accuracy: 0.7645 - val_loss: 0.4812 - learning_rate: 2.5000e-04\n",
      "Epoch 26/250\n",
      "\u001b[1m122/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8069 - loss: 0.4358 - val_accuracy: 0.7675 - val_loss: 0.4792 - learning_rate: 2.5000e-04\n",
      "Epoch 27/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4314 - val_accuracy: 0.7665 - val_loss: 0.4814 - learning_rate: 2.5000e-04\n",
      "Epoch 28/250\n",
      "\u001b[1m124/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8091 - loss: 0.4305 - val_accuracy: 0.7690 - val_loss: 0.4849 - learning_rate: 2.5000e-04\n",
      "Epoch 29/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.4376 - val_accuracy: 0.7685 - val_loss: 0.4812 - learning_rate: 2.5000e-04\n",
      "Epoch 30/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.4291 - val_accuracy: 0.7685 - val_loss: 0.4827 - learning_rate: 2.5000e-04\n",
      "Epoch 31/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4320 - val_accuracy: 0.7685 - val_loss: 0.4847 - learning_rate: 2.5000e-04\n",
      "Epoch 32/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8096 - loss: 0.4280 - val_accuracy: 0.7680 - val_loss: 0.4910 - learning_rate: 1.2500e-04\n",
      "Epoch 33/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4281 - val_accuracy: 0.7655 - val_loss: 0.4882 - learning_rate: 1.2500e-04\n",
      "Epoch 34/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.4301 - val_accuracy: 0.7685 - val_loss: 0.4856 - learning_rate: 1.2500e-04\n",
      "Epoch 35/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4268 - val_accuracy: 0.7665 - val_loss: 0.4925 - learning_rate: 1.2500e-04\n",
      "Epoch 36/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4223 - val_accuracy: 0.7670 - val_loss: 0.4908 - learning_rate: 1.2500e-04\n",
      "Epoch 37/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.4207 - val_accuracy: 0.7685 - val_loss: 0.4899 - learning_rate: 1.2500e-04\n",
      "Epoch 38/250\n",
      "\u001b[1m124/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.4199 - val_accuracy: 0.7695 - val_loss: 0.4891 - learning_rate: 1.2500e-04\n",
      "Epoch 39/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4225 - val_accuracy: 0.7690 - val_loss: 0.4915 - learning_rate: 1.2500e-04\n",
      "Epoch 40/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.4238 - val_accuracy: 0.7680 - val_loss: 0.4913 - learning_rate: 1.2500e-04\n",
      "Epoch 41/250\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4223 - val_accuracy: 0.7690 - val_loss: 0.4909 - learning_rate: 1.2500e-04\n",
      "\n",
      "ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì  ì„ê³„ê°’ íƒìƒ‰ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "---------------------------------------------\n",
      "ğŸš€ ìµœì  ì„ê³„ê°’ ë°œê²¬: 0.67\n",
      "ìµœì¢… Accuracy: 0.8105\n",
      "ìµœì¢… F1-Score: 0.7413\n",
      "---------------------------------------------\n",
      "ë”¥ëŸ¬ë‹ ëª¨ë¸ ë° ìµœì¢… ì„±ëŠ¥ ì§€í‘œ ì €ì¥ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ëŠ” ìˆ¨ê²¨ë‘˜ê²Œìš”\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° ê¸°ì´ˆ ê°€ê³µ\n",
    "print(\"ë”¥ëŸ¬ë‹ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "# íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©ì í™˜ê²½ì— ë§ì¶° ë¶ˆëŸ¬ì˜µë‹ˆë‹¤\n",
    "df = pd.read_csv('../data/spotify_churn_dataset.csv')\n",
    "\n",
    "# ì‹ë³„ì ì»¬ëŸ¼ì€ í•™ìŠµì— ë°©í•´ë˜ë‹ˆ ì œê±°í•©ë‹ˆë‹¤\n",
    "if 'user_id' in df.columns:\n",
    "    df = df.drop(columns=['user_id'])\n",
    "\n",
    "# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§: ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•´ ì˜ë¯¸ ìˆëŠ” ë³€ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤\n",
    "df['ad_burden'] = df['ads_listened_per_week'] / (df['listening_time'] + 1)\n",
    "df['satisfaction_score'] = df['songs_played_per_day'] * (1 - df['skip_rate'])\n",
    "df['time_per_song'] = df['listening_time'] / (df['songs_played_per_day'] + 1)\n",
    "\n",
    "X = df.drop(columns=['is_churned'])\n",
    "y = df['is_churned']\n",
    "\n",
    "# 2. ë°ì´í„°ì…‹ ë¶„ë¦¬ (Train 60% / Val 20% / Test 20%)\n",
    "# ì „ì²´ì—ì„œ ë¨¼ì € 20%ë¥¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë–¼ì–´ë†“ìŠµë‹ˆë‹¤\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ë‚¨ì€ 80%ë¥¼ ë‹¤ì‹œ 75:25ë¡œ ë‚˜ëˆ„ì–´ ìµœì¢…ì ìœ¼ë¡œ 60% í•™ìŠµ, 20% ê²€ì¦ ì„¸íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "# 3. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "numerical_cols = [\n",
    "    'age', 'listening_time', 'songs_played_per_day', 'skip_rate', \n",
    "    'ads_listened_per_week', 'offline_listening',\n",
    "    'ad_burden', 'satisfaction_score', 'time_per_song'\n",
    "]\n",
    "categorical_cols = ['gender', 'country', 'subscription_type', 'device_type']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°(Train)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì „ì²˜ë¦¬ê¸°ë¥¼ í•™ìŠµì‹œí‚¤ê³  ëª¨ë“  ë°ì´í„°ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# 4. BorderlineSMOTE ì ìš© (ì¤‘ìš”: ì˜¤ì§ í•™ìŠµ ë°ì´í„°ì—ë§Œ ì ìš©í•´ì„œ ì˜¤ì—¼ì„ ë°©ì§€í•©ë‹ˆë‹¤)\n",
    "print(\"í•™ìŠµ ë°ì´í„°ì—ë§Œ SMOTE ì ìš© ì¤‘... (ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ë³´ì¡´)\")\n",
    "bsmote = BorderlineSMOTE(random_state=42, kind='borderline-1')\n",
    "X_train_res, y_train_res = bsmote.fit_resample(X_train_proc, y_train)\n",
    "\n",
    "# 5. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„¤ê³„ (Sequential DNN)\n",
    "input_dim = X_train_res.shape[1]\n",
    "model = Sequential([\n",
    "    Dense(512, input_dim=input_dim, activation='swish'),\n",
    "    BatchNormalization(), Dropout(0.4),\n",
    "    Dense(256, activation='swish'),\n",
    "    BatchNormalization(), Dropout(0.4),\n",
    "    Dense(128, activation='swish'),\n",
    "    BatchNormalization(), Dropout(0.3),\n",
    "    Dense(64, activation='swish'),\n",
    "    BatchNormalization(), Dropout(0.3),\n",
    "    Dense(32, activation='swish'),\n",
    "    BatchNormalization(), Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(f\"\\nëª¨ë¸ êµ¬ì¡°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. (ì…ë ¥ ì°¨ì›: {input_dim})\")\n",
    "\n",
    "# 6. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "print(\"í•™ìŠµ ì‹œì‘...\")\n",
    "EPOCHS = 250\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0)\n",
    "checkpoint = ModelCheckpoint('../models/spotify_dl_model.h5', monitor='val_accuracy', save_best_only=True, verbose=0)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_res, y_train_res, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=64, \n",
    "    validation_data=(X_val_proc, y_val), # ë¶„ë¦¬í•´ë‘” ê²€ì¦ ë°ì´í„°ë¥¼ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint], \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7. ìµœì ì˜ ì„ê³„ê°’(Threshold) ì°¾ê¸°\n",
    "print(\"\\nìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìµœì  ì„ê³„ê°’ íƒìƒ‰ ì¤‘...\")\n",
    "best_model = tf.keras.models.load_model('../models/spotify_dl_model.h5')\n",
    "y_pred_proba = best_model.predict(X_test_proc).flatten()\n",
    "\n",
    "thresholds = np.arange(0.3, 0.7, 0.01)\n",
    "best_thresh, best_f1, best_acc = 0.5, 0, 0\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_temp = (y_pred_proba >= thresh).astype(int)\n",
    "    f1_temp = f1_score(y_test, y_pred_temp)\n",
    "    \n",
    "    if f1_temp > best_f1:\n",
    "        best_f1 = f1_temp\n",
    "        best_acc = accuracy_score(y_test, y_pred_temp)\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(f\"ğŸš€ ìµœì  ì„ê³„ê°’ ë°œê²¬: {best_thresh:.2f}\")\n",
    "print(f\"ìµœì¢… Accuracy: {best_acc:.4f}\")\n",
    "print(f\"ìµœì¢… F1-Score: {best_f1:.4f}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# 8. ê²°ê³¼ ë° ì „ì²˜ë¦¬ê¸° ì €ì¥\n",
    "if not os.path.exists('../models'): os.makedirs('../models')\n",
    "joblib.dump(preprocessor, '../models/dl_preprocessor.pkl')\n",
    "\n",
    "metrics_file = '../data/model_metrics.json'\n",
    "final_metrics = {}\n",
    "\n",
    "if os.path.exists(metrics_file):\n",
    "    try:\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            final_metrics = json.load(f)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ë”¥ëŸ¬ë‹ ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸\n",
    "final_metrics['Deep Learning (DNN)'] = {\n",
    "    'Accuracy': best_acc, \n",
    "    'F1-Score': best_f1,\n",
    "    'Best Threshold': float(best_thresh)\n",
    "}\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=4)\n",
    "\n",
    "print(\"ë”¥ëŸ¬ë‹ ëª¨ë¸ ë° ìµœì¢… ì„±ëŠ¥ ì§€í‘œ ì €ì¥ ì™„ë£Œ.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_basic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
